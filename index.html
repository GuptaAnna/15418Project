<!DOCTYPE html>
<html>
<title>15418 Project</title>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3.css">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
<style>
body {font-family: "Lato", sans-serif}
  
table {
    border-collapse: collapse;
    width: 100%;
}

td, th {
    border: 1px solid #dddddd;
    text-align: left;
    padding: 8px;
}
</style>
<body>

<!-- Navbar -->
<div class="w3-top">
  <div class="w3-bar w3-black w3-card-2">
    <a class="w3-bar-item w3-button w3-padding-large w3-hide-medium w3-hide-large w3-right" href="javascript:void(0)" onclick="myFunction()" title="Toggle Navigation Menu"><i class="fa fa-bars"></i></a>
    <a href="#" class="w3-bar-item w3-button w3-padding-large">HOME</a>
    <a href="#proposal" class="w3-bar-item w3-button w3-padding-large w3-hide-small">PROPOSAL</a>
    <a href="#checkpoint" class="w3-bar-item w3-button w3-padding-large w3-hide-small">CHECKPOINT</a>
    <a href="#report" class="w3-bar-item w3-button w3-padding-large w3-hide-small">FINAL REPORT</a>
  </div>
</div>

<!-- Page content -->
<div class="w3-content" style="max-width:2000px;margin-top:46px">
  
  <!-- The Home Section -->
  <div class="w3-container w3-content w3-center w3-padding-32" style="max-width:800px">
    <!-- Home -->
    <h1> Solving the 15-Puzzle with Parallel A* </h1>
    <h3> William Xiao (williamx), Anna Gupta (annag) </h3>
    <a href="https://github.com/GuptaAnna/15418Project"> View Our Code on Github </a>
  </div>

  <!-- The Proposal Section -->
  <div class="w3-container w3-content w3-center w3-padding-32" style="max-width:800px" id="proposal">
    <h1> Proposal </h1>
    
    <p class="w3-justify">
    <font size="5"> Title </font>
    <br>
    Solving the 15-Puzzle with Parallel A*
    </p>
    
    <p class="w3-justify">
    <font size="5"> Summary </font>
    <br>
    We will implement a parallel version of the A* algorithm to solve the 15-Puzzle with minimal moves on the Gates 
    or latedays machines.
    </p>
    
    <p class="w3-justify">
    <font size="5"> Background </font>
    <br>
    The 15-Puzzle consists of a 4x4 frame of square tiles (numbered from 1 to 15), with one tile missing. 
    The object of the game is to place the tiles in numerical order by sliding tiles, using the empty space.
    The puzzle can come in different sizes; in general, a NxN frame will use tiles numbered from 1 to N<sup>2</sup> - 1. 
      
    <br>
    The game can be represented as a graph, with nodes being the state of the board and edges representing an action 
    (sliding a particular tile). We would like to implement a graph-searching algorithm to find the shortest sequence of moves
    to solve the puzzle. 
      
    <br>
    In graph-search algorithms, a heuristic ranks edges from a node, based on an algorithm. This decides which actions are preferable, 
    given the state of the game. The 15-Puzzle is perfect for an algorithm involving heuristics. One possible heuristic for the puzzle 
    uses the taxicab distances for each tile (difference in distance between actual and desired positions). This opens the door for us 
    to use A* (or other heuristic algorithms) to solve the puzzle. 
    
    <br>
    <center>
    <img src="Fifteen_puzzle.png" alt="Fifteen Puzzle">
    </center>
    </p>
    
    <p class="w3-justify">
    <font size="5"> The Challenge </font>
    <br>
    Unlike other graph-search algorithms, A* is difficult to implement in parallel due to the heuristic. The sequential version of
    the algorithm utilizes a priority queue, ranking the nodes by cost or preference. In an iteration, the least-cost node is popped 
    from the priority queue, information is updated, and the neighbors of the node are added to the queue. These neighbors could 
    have a higher preference than nodes previously existing in the queue, making it difficult to utilize multiple threads. It might 
    not be viable to have multiple threads working on different nodes in the queue - since the second-preferred node in the queue 
    may not be the first-preferred node after the iteration. 
    </p>
    
    <p class="w3-justify">
    <font size="5"> Resources </font>
    <br>
    We will start writing code from scratch. We will research A* and other heuristic algorithms to determine 
    one that is optimal for solving the 15-Puzzle. We will also determine a benchmark for speed-up that can 
    be acquired by parallelizing A* by reading research papers. We will utilize the Gates or latedays clusters 
    for our project. 
    </p>
    
    <p class="w3-justify">
    <font size="5"> Goals &amp; Deliverables </font>
    </p>
    Goals: 
    <ul class="w3-justify">
    <li> Implement a sequential version of A* in the context of the 15-Puzzle </li>
    <li> Research the A* algorithm and determine a desired speed-up goal between sequential and parallel versions </li>
    <li> Implement a parallel version using CUDA, achieving the desired speed-up </li>
    <li> Compare speed-up across varying number of threads and determine an optimal number of threads to use</li>
    <li> Test our implementation on larger versions of the 15-Puzzle, varying the width of the board</li>
    </ul> 
      
    If time permits:
    <ul class="w3-justify">
    <li> Experiment with variants of the A* algorithm and compare which results in the largest speedup</li>
    <li> Achieve parallelism through different method - for example, using OpenMP </li>
    </ul> 
    
    <p class="w3-justify">
    We will construct a rubric for our work by researching prior attempts to parallelize A* and the speed-ups they received. 
    Ideally, we would like to achieve as close to the best speed-up achieved as possible.
    </p>
    
    <p class="w3-justify">
    <br>
    <font size="5"> Platform Choice </font>
    <br>
    CUDA will give us access to a large number of threads - which will be useful in solving large instances of the puzzle. 
    In addition, we can utilize thread blocks and shared memory as a form of communication between the threads. 
    </p>
    
    <p class="w3-justify">
    <font size="5"> Schedule </font>
    </p>
    
    <table>
      <tr>
        <th>Week of:</th>
        <th>Task</th>
      </tr>
      <tr>
        <td>April 17</td>
        <td>Determine benchmark for speed-up; Implement a sequential version of A*</td>
      </tr>
      <tr>
        <td>April 24</td>
        <td>Research and implement a parallel version of A*</td>
      </tr>
      <tr>
        <td>May 1</td>
        <td>Test and make implementation scalable on different sized grids </td>
      </tr>
      <tr>
        <td>May 8</td>
        <td>Optimize implementation and finish final report + presentation</td>
      </tr>
    </table>
  </div>
    
  <!-- The Checkpoint Section -->
  <div class="w3-container w3-content w3-center w3-padding-32" style="max-width:800px" id="checkpoint">
    <h1> Checkpoint </h1>
    
    <p class="w3-justify"> 
    <font size="5"> Work Completed </font>
    <br>
    The goal of our project is to implement a parallel version of A* to solve the 15-Puzzle. 
    We've successfully implemented a sequential version of the algorithm. In particular: 
    </p>
    <ul class="w3-justify">
    <li> We created an abstract State class, representing the state of the game at a point in time. The class has both implemented
         and virtual methods. The implemented methods are general and related to A*, while the virtual methods are defined 
         in the extending class. This design generalizes the state class, allowing it to be used for different games. </li>
    <li> We created a Board class to extend the State class. We represent the game board with a 2-D array of integers, 
         storing the numbers of the tiles. We allow a board to be created in two ways: 
         <ul>
           <li> Randomly generating a permutation of the numbers in the range 1 to n. We check if the board layout has a valid
                solution (in the context of the 15-Puzzle); if not, we fix it by swapping two numbers. </li>
           <li> Starting from the goal board and randomly making valid moves </li>
         </ul>
    </li> 
    <li> We implemented our own priority queue class, as the c++ library does not support an efficient remove function. We utilize 
          this priority queue implementation in the A* algorithm.  </li>
    <li> We developed a sequential version of the A* algorithm using the State class. Going forward, our parallel version 
      will also use the State class. </li>
    </ul> 
    
    <p class="w3-justify"> 
    <font size="5"> Updated Schedule </font>
    <br>
    </p>
    
    <table>
      <tr>
        <th>Time Period:</th>
        <th>Task: William</th>
        <th>Task: Anna</th>
      </tr>
      <tr>
        <td>April 24-27</td>
        <td>Brainstorm different methods of parallelizing A*</td>
        <td>Research and understand shared priority queues</td>
      </tr>
      <tr>
        <td>May 2-5</td>
        <td>Implement parallel version of A*</td>
        <td>Implement parallel version of A*</td>
      </tr>
      <tr>
        <td>May 6-9</td>
        <td>Test implementation on larger grids + make optimizations as necessary </td>
        <td>Compare speed-up across threads + determine optimal number of threads</td>
      </tr>
      <tr>
        <td>May 10-12</td>
        <td>Finish final report + presentation</td>
        <td>Finish final report + presentation</td>
      </tr>
    </table>
    
    <p class="w3-justify"> 
    <font size="5"> Updated Goals &amp; Deliverables </font>
    <br>
    So far, we are on schedule, as detailed in our proposal. We have begun researching possible ways to parallelize A* and
    designing our implementation. In previous attempts of parallel A*, researchers have sacrificed optimality of the solution
    for speed. Therefore, the parallel versions, although fast, may not return the best solution.
    <br>
    Going forward, one concern we have is whether we will have to sacrifice optimality as well. Initially, we hoped to achieve 
    great speed-up while also returning the optimal solution. If time permits, we will implement multiple versions of parallel
    A*, varying in optimality of the solution. From this, we can compare the correlation between speed-up and suboptimality. 
    <br>
    </p>
    Updated Goals:
    <ul class="w3-justify">
    <li> Optimize State and/or Board classes to improve both sequential and parallel efficiency </li>
    <li> Determine a desired speed-up goal for the parallel algorithm compared to the baseline </li>
    <li> Implement a parallel version using CUDA, based on results of research papers </li>
    <li> Determine an optimal number of threads to use for the parallel version </li>
    <li> Test our implementation on larger board sizes of the puzzle </li>
    </ul> 
    
    <p class="w3-justify"> 
    <font size="5"> Other Information </font>
    <br>
    For the parallelism competition, we will provide both a demo and graph. The demo will show the steps in order to solve the 
    puzzle optimally. Therefore, the user could follow the printed steps to solve a randomly generated puzzle. 
    We will also present a graph to demonstrate
    speed-up between the sequential version that we've already implemented and the parallel version that we will implement in the future. 
    </p>
  </div>

  <!-- The Final Report Section -->
  <div class="w3-container w3-content w3-center w3-padding-32" style="max-width:800px" id="report">
    <h1> Final Report </h1>
    
    <p class="w3-justify">
    <font size="5"> Summary </font>
    <br>
    We parallelized the A* algorithm, for use in solving the 15-Puzzle optimally. To achieve parallelism, we utilized pthreads and 
    tested on the GHC machines. 
    </p>
    
    <p class="w3-justify">
    <font size="5"> Background </font>
    <br>
      A*: <br> A* is a heuristic-based pathfinding algorithm. Given a weighted-graph and two nodes, the algorithm finds the shortest path between them. 
      A algorithm uses two functions: we'll name them <b>g(n)</b> and <b>h(n)</b>. <b>g(n)</b> is the cost from the start to <i>n</i>, or 
      the sum of the edges connecting start and <i>n</i>. <b>h(n)</b> is a heuristic, a function that estimates the cheapest cost from 
      <i>n</i> to the goal. This function must be admissible, meaning it never overestimates the actual cost. Together, <b>key(n)</b> = 
      g(n) + h(n), which represents the priority of the node. A lower key value means a lower cost is incurred to travel
      through that node, ensuring a higher priority. The algorithm will explore nodes in order of priority. 
      
      <br><br>
      15-Puzzle: <br> This puzzle fits perfectly in the context of A*. Each board arrangement represents a node in the graph, with edges 
      representing possible moves in the game. Each edge will have a weight of 1, so <b>g(n)</b> represents the smallest number of moves 
      to reach <i>n</i> from start. Using A*, we can find the shortest path between the start and goal arrangements. 
      
      <br><br>
      Priority Queue: <br> The order of expansion is maintained by a priority queue. We begin by pushing the start node into the queue. 
      Then, we repeat the following steps:
    </p>
      <ul class="w3-justify">
      <li> Pop the node with the lowest key value </li>
      <li> Iterate over the neighbors of the node </li>
      <li> If the neighbor has been expanded before, we ignore it </li>
      <li> Else, we push it to the priority queue, if not there. In addition, we update the key value, if possible. </li>
      </ul>
    <p class="w3-justify">
      Sequentially, one node would be popped from the queue at a time. We saw potential parallelism in this process in that 
      many nodes can be popped and processed at the same time. 
    
    </p>  
      <p class="w3-justify">
      Hash Table: <br> To represent a board, we created a Board class. For every board, we wished to create
      only one Board object. To keep track of the boards created, we kept a hash table, ensuring a unique object for each board in the
      game. 
    </p>
    
    <p class="w3-justify">
    <font size="5"> Previous Ideas </font>
    <br>
    We brainstormed and researched many ideas to parallelize the A* algorithm, all of which had flaws: 
    </p>  
    <ul class="w3-justify">
      <li> Bidirectional search: In this approach, we run two simultaneous A* processes, 
           one branching from the start node, the other branching from the goal node. The two processes would meet in the middle, 
           achieving potential speedup by a factor of 2. However, this approach does not scale beyond 2 threads. We hoped to achieve
           further parallelism than this approach would. </li>
      <li> Fine-grained priority queue: This would allow multiple threads to insert / pop from the priority queue simultaneously. 
           However, there would be high contention on the root node, since all threads would strive to access it. This would 
           severly limit parallelism. </li>
      <li> Multiple independent A* processes: With this approach, we would run independent A* processes on the neighbors of the 
           start node. This seems like it's achieving parallelism, since multiple paths are being explored in parallel. However, 
           the processes are likely to expand the same states. Due to low communication between threads, redundant work is being
           executed, resulting in little to no speed-up. </li>
      </ul>
      
    <p class="w3-justify">
    <font size="5"> Our Final Approach </font>
    <br>
    Our final idea involved spawning multiple threads, each popping and inserting into a coarse-grained priority queue simultaneously. 
    However, due to high contention on the root node and low arithmetic intensity (a thread accesses the priority queue frequently),  
    speed-up would be minimal. Therefore, we split the data structure into multiple priority queues. Our TSPriorityQueue class contained
    a vector of priority queues, each being coarse-grained. Specifically, the length of the vector is equal to the number of threads 
    in the system. Therefore, each thread accesses from its own priority queue with no contention, increasing parallelism.  
    <br><br>
    We created a hash function, mapping a Board object (a board in the game) to a value. This value mod n, n being the number
    of threads, is its index into the TSPriorityQueue, mapping to a priority queue. Since our hash function is randomized, 
    the neighbors of a node are likely to be hashed into different priority queues. This increases communication between threads and 
    balances load among the priority queues. Along with the vector of priority queues, we also have a vector of hash tables. Each priority
    queue is paired with a hash table, and a hash table contains the Board objects that have been pushed into its matching priority queue. 
    This avoids creating duplicate Board objects to represent the same board arrangement. 
    <br><br>
    Our parallel version saw speed-up; however, we wished to ensure optimality of the solution outputted. The sequential A* was optimal, 
    because it pushed nodes in monotonically ascending order. Therefore, if we pop the goal state, we are assured that the key value
    seen is the lowest possible key value. However, this is not guaranteed when using multiple threads. For example, thread 0 could pop
    off a goal state with key value of 100. At the same time, thread 5 could pop off another node with key value of 50. This node could
    then lead to the goal state with a lower key value than 100. To solve this issue, we replicated assignment 4 and created a handle-tick
    function. This function would check if the goal state has been expanded and, if so, compares its key value to the global minimum 
    of TSPriorityQueue. If the goal state's key value is smaller, then we are assured no smaller path to the goal state
    exists. 
    </p>
    
    <p class="w3-justify">
    <font size="5"> Further Optimization </font>
    <br>
    In our parallel implementation, each thread is mapped to a single priority queue. However, we wished to further lower 
    contention and increase flexibility. We made further optimizations by increasing the number of priority queues through an integer "multiplier". 
    Therefore, we would create <i>multiplier</i> number of priority queues for each thread, rather than 1 per. 
    </p>
    
    <p class="w3-justify">
    <font size="5"> Results </font>
    <br>
    
    <center>
    <img src="graphs/runtime.png" alt="Runtime"><br>
    Figure 1
    </center>  
    To produce this graph, we ran 3 files, each with a 4x4 board input. We compared our sequential implementation with ou parallel version,
    varying the number of threads used. We ran this code on the GHC machines, which has 8 hyperthreaded cores. The initial increase in 
    execution time (between sequential and 2-threaded versions) could be due to large overhead in spawning threads. As thread count increases,
    execution time significantly decreases. 
      
    <center>
    <img src="graphs/speedup.png" alt="Speedup"><br>
    Figure 2
    </center>  
    This displays the same data as Figure 1. On the y-axis, we plot speed-up, rather than execution time. The 12-threaded version
    sees 2x speed-up compared to the sequential version. 
      
    <center>
    <img src="graphs/runtime_optimized.png" alt="Runtime Optimized"><br>
    Figure 3
    </center>  
    This graph runs the same files as before. All factors are constant, except we utilize 128 priority queues per thread, 
    rather than 1 per. We chose 128 after meticulous testing. Too few priority queues results in contention, whereas 
    too many priority queues is wasteful of memory. Compared to Figure 1, there is a sharper decrease in execution time, with the 
    12-threaded version taking significantly less time. 
      
    <center>
    <img src="graphs/speedup_optimized.png" alt="Speedup Optimized"><br>
    Figure 4
    </center>  
    This displays the same data as Figure 3, plotting speed-up rather than execution time. Recall that with 1 priority queue per thread, 
    we achieved a 2x speedup. With the increase in priority queues, we achieve a 5-6x speedup. This optimization was very successful. 
    
    </p>
    
    <p class="w3-justify">
    <font size="5"> Challenges </font>
    <br>
    When developing our implementation, we discovered the C++ library does not support an "update" function for priority queues. Therefore, 
    in order to modify the key value of an element in the queue, we must delete the element and insert again with the updated key value. 
    To circumvent this issue, we created our own implementation of a priority queue, supporting the insert operation. 
    We also implemented a thread-safe data structure, consisting of a vector of coarse-grained priority queues. Each coarse-grained priority
    queue was paired with a coarse-grained hash table, containing all the Board objects that had been pushed into the priority queue. 
    Therefore, each Board mapped to a hash table-priority queue duo, through a randomized hash function. 
    <br><br>
    It was difficult to create an efficient, load-balanced hash function. Initially, our parallel version did not see great speed-up. We 
    discovered this was a result of a poor hash function, resulting in load imbalance and low speed-up.  
    </p>
    
    <p class="w3-justify">
    <font size="5"> References </font>
    <br>
    None
    </p>
    
    <p class="w3-justify">
    <font size="5"> Distribution of Work </font>
    <br>
    Equal work was done by each group member. 
    </p>
  </div>
  
  
<!-- End Page Content -->
</div>

</body>
</html>
